{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "    \n",
    "# <center> <font color= #000047> Modulo III: Aprendizaje supervizado: Regresión Lineal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Aprendizaje Supervizado se podría definir como un tipo de aprendizaje en IA en el que un algoritmo es entrenado con variables que incluyen los valores que queremos predecir; a estos valores conocidos se les llama `“etiquetas”` y se usan también para la evaluación del modelo. El aprendizaje supervisado se puede subdividir en dos tipos: \n",
    "\n",
    "- Clasificación\n",
    "\n",
    "- Regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación\n",
    "\n",
    "En cuanto a clasificación, el objetivo es predecir las etiquetas de clase categóricas de nuevos registros, con base en observaciones pasadas. Dependiendo de la etiqueta, se puede decir que la clasificación es binaria o multiclase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión\n",
    "\n",
    "Respecto a regresión, se trata del proceso estadístico predictivo en el que el modelo intenta predecir un valor continuo (como ventas, precio, calificaciones) mediante la relación entre variables dependientes e independientes. Es decir, se encuentra una ecuación en la que se sustituyen los valores de las variables y como resultado se obtiene el valor a predecir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunos algortimos de Aprendizaje Supervizado\n",
    "\n",
    "- **Regresión lineal:** Se trata de una regresión en la que al graficar la ecuación se forma una línea recta. Para obtener dicha ecuación, se usa el método de los cuadrados mínimos.\n",
    "\n",
    "\n",
    "- **Regresión logística:** Es una regresión usada principalmente en problemas de clasificación binaria. A pesar de la aparente incongruencia, se trata de una regresión porque el resultado de la ecuación es la probabilidad de que pertenezca a una clase, que dependiendo del umbral que se utilice, se clasifica como positivo o negativo.\n",
    "\n",
    "\n",
    "- **Support Vector Machine (SVM):** Típicamente se usa para problemas de clasificación, pero también se puede usar para regresión. En este algoritmo se construye un hiperplano que separa las clases de datos lo más posible.\n",
    "\n",
    "\n",
    "- **Árboles de decisión:** Algoritmo de clasificación similar a un diagrama de flujo, en el que se evalúan valores en cada nodo para llegar a una clasificación al final.\n",
    "\n",
    "\n",
    "- **Random Forest:** Este algoritmo consiste en combinar una gran cantidad de árboles de decisión independientes entre sí para reducir la varianza. Debido al conjunto de árboles, se le dio el nombre de “bosque”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/a/a8/Regression_pic_assymetrique.gif\" width=\"400px\" height=\"125px\" />\n",
    "\n",
    "> El **ajuste de curvas** es el proceso de construir una curva (función), que sea el mejor ajuste a una serie de puntos. Las curvas ajustadas pueden ser usadas como asistencia en la visualización de datos, para inferir valores de una función donde no hay datos disponibles, y para resumir la relación entre variables.\n",
    "\n",
    "**Referencia**:\n",
    "- https://en.wikipedia.org/wiki/Curve_fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introducción\n",
    "\n",
    "Consideremos un polinomio de grado uno:\n",
    "\n",
    "$$y = \\beta_1 x + \\beta_0.$$\n",
    "\n",
    "Esta es una **línea recta** que tiene pendiente $\\beta_1$. Sabemos que habrá una línea conectando dos puntos cualesquiera. Por tanto, *una ecuación polinómica de primer grado es un ajuste perfecto entre dos puntos*.\n",
    "\n",
    "Si consideramos ahora un polinomio de segundo grado,\n",
    "\n",
    "$$y = \\beta_2 x^2 + \\beta_1 x + \\beta_0,$$\n",
    "\n",
    "este se ajustará exactamente a tres puntos. Si aumentamos el grado de la función a la de un polinomio de tercer grado, obtenemos:\n",
    "\n",
    "$$y = \\beta_3 x^3 + \\beta_2 x^2 + \\beta_1 x + \\beta_0,$$\n",
    "\n",
    "que se ajustará a cuatro puntos.\n",
    "\n",
    "**Ejemplos**\n",
    "1. Encontrar la línea recta que pasa exactamente por los puntos $(0,1)$ y $(1,0)$.\n",
    "2. Encontrar la parábola que pasa exactamente por los puntos $(-1,1)$, $(0,0)$ y $(1,1)$.\n",
    "\n",
    "**Solución**\n",
    "1. Consideramos $y=\\beta_1 x + \\beta_0$. Evaluando en el punto $(0,1)$, obtenemos $\\beta_1(0) + \\beta_0 = 1$. Ahora, evaluando en el punto $(1,0)$, obtenemos $\\beta_1(1) + \\beta_0 = 0$. De esta manera,\n",
    "$$\\left[\\begin{array}{cc} 1 & 0 \\\\ 1 & 1\\end{array}\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1\\end{array}\\right]=\\left[\\begin{array}{c} 1 \\\\ 0\\end{array}\\right].$$\n",
    "Resolviendo, $\\beta_0=-\\beta_1=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar numpy y el matplotlib.pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Encontrar beta_0 y beta_1 resolviendo el sistema\n",
    "help(np.linalg.solve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,0],\n",
    "              [1,1]])\n",
    "b = np.array([1,0])\n",
    "\n",
    "beta = np.linalg.solve(A,b)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta = A^-1 * b\n",
    "# A*beta = b\n",
    "#A^(-1)*A*beta = A^(-1)*b\n",
    "# I*beta = A^(-1)*b\n",
    "# beta = A^(-1)*b\n",
    "\n",
    "beta = np.linalg.inv(A).dot(b)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = (0,1)\n",
    "P2 = (1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la recta encontrada junto con los puntos\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(P1[0],P1[1],'ro',ms=10,label = f'${P1}$')\n",
    "plt.plot(P2[0],P2[1],'ro',ms=10,label = f'${P2}$')\n",
    "x_num = np.linspace(-1,2)\n",
    "y_num = beta[0] + beta[1]*x_num\n",
    "\n",
    "plt.plot(x_num, y_num, 'b', lw=3, label=f'$y ={np.round(beta[0],2)} + {np.round(beta[1],2)}x$')\n",
    "plt.xlabel('$x$')\n",
    "plt.xlabel('$y$')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Consideramos $y=\\beta_2 x^2 + \\beta_1 x + \\beta_0$. Evaluando en el punto $(-1,1)$, obtenemos $\\beta_2(-1)^2 + \\beta_1(-1) + \\beta_0 = 1$. Ahora, evaluando en el punto $(0,0)$, obtenemos $\\beta_2(0)^2 + \\beta_1(0) + \\beta_0 = 0$. Finalmente, evaluando en el punto $(1,1)$, obtenemos $\\beta_2(1)^2 + \\beta_1(1) + \\beta_0 = 1$. De esta manera,\n",
    "$$\\left[\\begin{array}{ccc} 1 & -1 & 1 \\\\ 1 & 0 & 0 \\\\ 1 & 1 & 1 \\end{array}\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{array}\\right]=\\left[\\begin{array}{c} 1 \\\\ 0 \\\\ 1 \\end{array}\\right].$$\n",
    "Resolviendo, $\\beta_0=\\beta_1=0$ y $\\beta_2=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar beta_0, beta_1 y beta_2\n",
    "A = np.array([[1,-1,1],\n",
    "              [1,0,0],\n",
    "              [1,1,1]])\n",
    "b = np.array([1,0,1])\n",
    "\n",
    "# solucion utilizando la inversa de la mat A\n",
    "beta = np.linalg.inv(A).dot(b)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(np.linalg.solve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método de solucion de ecuaciones (como entrada se necesitan matrices y vectores)\n",
    "beta = np.linalg.solve(A,b)\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo los puntos\n",
    "P1 = (-1,1)\n",
    "P2 = (0,0)\n",
    "P3 = (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la parabola junto con los puntos\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(P1[0],P1[1],'ro',ms=10,label = f'${P1}$')\n",
    "plt.plot(P2[0],P2[1],'ro',ms=10,label = f'${P2}$')\n",
    "plt.plot(P3[0],P3[1],'ro',ms=10,label = f'${P3}$')\n",
    "x_num = np.linspace(-2,2)\n",
    "# y = b2x^2 + b1x + b0\n",
    "y_num = beta[0] + beta[1]*x_num + beta[2]*x_num**2\n",
    "\n",
    "\n",
    "plt.plot(x_num, y_num, 'b', lw=3, label=f'$y ={np.round(beta[0],2)} + {np.round(beta[1],2)}x + {np.round(beta[2],2)}x^2$')\n",
    "plt.xlabel('$x$')\n",
    "plt.xlabel('$y$')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué tienen en común los anteriores problemas?\n",
    "Las curvas están completamente determinadas por los puntos (datos limpios, suficientes y necesarios).\n",
    "\n",
    "Esto se traduce en que, al llevar el problema a un sistema de ecuaciones lineales, existe una única solución: **no hay necesidad, ni se puede optimizar nada**.\n",
    "\n",
    "¿Tendremos datos así de '*bonitos*' en la vida real?\n",
    "\n",
    "La realidad es que los datos que encontraremos en nuestra vida profesional se parecen más a esto..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un conjunto de puntos ruidosos a partir de una recta\n",
    "N =100\n",
    "x = np.linspace(0,10,N)\n",
    "y = 10 + 2*x + np.random.normal(loc=0,scale=2,size=(N,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(x,y,'xr',label='datos')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo ajustamos una curva a esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problema básico\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg\" width=\"400px\" height=\"125px\" />\n",
    "\n",
    "Consideramos que tenemos un conjunto de n pares ordenados de datos $(x_i,y_i)$, para $i=1,2,3,\\dots,n$.\n",
    "\n",
    "### ¿Cuál es la recta que mejor se ajusta a estos datos?\n",
    "Consideramos entonces ajustes de la forma $\\hat{f}(x) = \\beta_0+\\beta_1 x = \\left[1 \\quad x\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\end{array}\\right]=\\left[1 \\quad x\\right]\\boldsymbol{\\beta}$ (lineas rectas).\n",
    "\n",
    "Para decir '*mejor*', tenemos que definir algún sentido en que una recta se ajuste *mejor* que otra.\n",
    "\n",
    "**Mínimos cuadrados**: el objetivo es seleccionar los coeficientes $\\boldsymbol{\\beta}=\\left[\\beta_0 \\quad \\beta_1 \\right]^T$, de forma que la función evaluada en los puntos $x_i$ ($\\hat{f}(x_i)$) aproxime los valores correspondientes $y_i$.\n",
    "\n",
    "La formulación por mínimos cuadrados, encuentra los $\\boldsymbol{\\beta}=\\left[\\beta_0 \\quad \\beta_1 \\right]^T$ que minimiza\n",
    "$$\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-\\hat{f}(x_i))^2=\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-(\\beta_0+ \\beta_1x_i))^2=\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-\\left[1 \\quad x_i\\right]\\boldsymbol{\\beta})^2=\\frac{1}{2n}\\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2,$$\n",
    "\n",
    "donde $\\boldsymbol{y}=\\left[y_1\\quad\\dots\\quad y_n\\right]^T$, y $\\boldsymbol{X}=\\left[\\begin{array}{ccc}1 & x_1\\\\ \\vdots & \\vdots \\\\ 1 & x_n\\end{array}\\right].$ Esto es,\n",
    "\n",
    "$$\\boldsymbol{\\beta}^{ls} = \\arg \\min_{\\boldsymbol{\\beta}} \\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que el problema anterior no es de programación lineal, ¿porqué?\n",
    "\n",
    "Para llevar a cabo la anterior minimización, la librería `SciPy` en su módulo `optimize` contiene la función `minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el módulo optimize de la librería scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros importantes:\n",
    "- fun: función $f(x)$, se debe definir antes de llamar minimize, como `def f(x): ... return ...`\n",
    "- x0: valor inicial. En una función no lineal, en general, hay múltiples mínimos. Dependiendo de la semilla caerá en uno de esos mínimos. Se ingresa como $x0 = \\text{np.array}([x_{01},\\dots,x_{0n}])$.\n",
    "- bounds: como en linprog.\n",
    "- constraints: funciones que definen las restricciones $g_i(x)$ y $h_j(x)$. Se definen igual que $f(x)$ y se ingresan como {'ineq': g_i, 'eq': h_j}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero debemos construir la función objetivo y la semilla inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir funcion objetivo y punto inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica de los puntos y la recta ajustada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/ex1data1.txt', names=['population', 'profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(data['population'], data['profit'])\n",
    "plt.xlabel('population')\n",
    "plt.ylabel('profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo matemático de la regresión lineal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es estimar el modelo:\n",
    "\n",
    "$$ \\hat{y} = \\beta_1 x + \\beta_0$$\n",
    "\n",
    "donde $\\beta_1$ es la pendiente y $\\beta_0$ es la distancia de la intersección con el eje y.\n",
    "\n",
    "Podemos estima mediante una ecuación matricial:\n",
    "\n",
    "$$\\hat{y}=X\\beta$$\n",
    "\n",
    "$$X=[x;1]$$\n",
    "$$\\beta=[\\beta_1 \\beta_0]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redordando la Función de costo \n",
    "\n",
    "La funcion de costo es el error cuadrático medio, qué deberemos minimizar.\n",
    "\n",
    "$$ J(\\beta) = \\frac{1}{2m}\\sum_{i=1}^m (\\hat{y}(x_i) - y_i)^2$$\n",
    "\n",
    "$\\beta = [\\beta_0, \\beta_1]$\n",
    "\n",
    "si derivamos parcialmente e igualamos a cero $\\frac{\\partial J(\\beta)}{\\partial \\beta}=0$\n",
    "\n",
    "### Ejercicio: encontrar mediante las derivadas parciales las ecuciones siguientes:\n",
    "\n",
    "\n",
    "tendríamos que las ecuaciones del **algoritmo de gradiente descendente** son:\n",
    "\n",
    "$$ \\beta_0 = \\beta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)$$\n",
    "\n",
    "$$ \\beta_1 = \\beta_1 - \\alpha \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)x_i$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficar un función de costo cualquiera\n",
    "x_quad = [n/10 for n in range(0,100)]\n",
    "y_quad = [(n-4)**2 + 5 for n in x_quad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(x_quad, y_quad, 'k--')\n",
    "plt.axis([0,10,0,30])\n",
    "plt.plot([1,2,3],[14,9,6], 'ro')\n",
    "plt.plot([5,7,8],[6,14,21], 'bo')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('J')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$X=[1;x]$$\n",
    "$$\\beta=[\\beta_0;\\beta_1]$$\n",
    "$$\\hat{y}=X^T\\beta = \\beta_1 x +\\beta_0$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=[1;x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algoritmo de gradiente descendente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicializamos los parámetros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es estimar el modelo:\n",
    "\n",
    "$$ \\hat{y} = ? x + ?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la recta resultamte que más se ajusta a lso datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#historial de costos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir un nuevo valor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Usando la librería de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['population'].values.reshape(-1,1)\n",
    "y=data['profit'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el modelo\n",
    "# y_hat = beta_1*x + beta_0\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando predicciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **model.coef**: Coeficientes que acompañan a la variable independiente $\\beta_1, ..., \\beta_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **model.intercept_**: Coeficiente de intercepción al eje de las abcisas $\\beta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la recta resultamte que más se ajusta a lso datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo obtenido:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ \\hat{y} = ? x + ?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predecir un nuevo elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otro ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Data/Position_Salaries.csv')\n",
    "datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datos['Level'].values.reshape(-1,1)\n",
    "y = datos['Salary'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar un modelo líneal que se ajuste a los datos\n",
    "#1.- entrenar un modelo con la linbrería sklearn\n",
    "\n",
    "#2.- predecir los valores de entrenamiento x\n",
    "\n",
    "#3.- Graficar el modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un modelo de regresión polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat = beta_2 x^2 + beta_1 x + beta_0\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtener el modelo polinomial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.- Graficar el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio : Predecir los niveles utilizando un modelo polinomial de grado 3\n",
    "\n",
    "- Crear un modelo polinomial de grado 3\n",
    "- Predecir los siguientes niveles: x_new=[11, 13, 15]\n",
    "- Graficar los salarios de los valores de x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
